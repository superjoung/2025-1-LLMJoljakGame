from fastapi import FastAPI
from pydantic import BaseModel
import chromadb
import uuid
from graph_flow import create_dynamic_graph

app = FastAPI()

# ğŸ”§ ë©”ëª¨ë¦¬ ê¸°ë°˜ DB ì´ˆê¸°í™” (ì„œë²„ ë„ë©´ ì‚­ì œë¨)
client = chromadb.Client()  # persist_directory ì—†ì´ ì‚¬ìš©
npc_collection = client.get_or_create_collection("npc_memory")
host_collection = client.get_or_create_collection("host_memory")


# ìš”ì²­ ëª¨ë¸
class UserInput(BaseModel):
    input: str
    npc: str

@app.post("/ask")
async def ask_npc(user_input: UserInput):
    compiled_graph = create_dynamic_graph(user_input.npc)
    # 1. ì»¬ë ‰ì…˜ ì„ íƒ
    collection = host_collection if user_input.npc == "ì‚¬íšŒì" else npc_collection

    # 2. ê¸°ì–µ ê²€ìƒ‰
    results = collection.query(
        query_texts=[user_input.input],
        n_results=1
    )
    memory_used = results["documents"][0] if results["documents"] else ""

    # 3. ì‚¬íšŒìë©´ GPT í˜¸ì¶œ ìƒëµ
    if user_input.npc == "ì‚¬íšŒì":
        response = f"(ê¸°ë¡ë¨) {user_input.input}"  # í‘œì‹œìš© ë©”ì‹œì§€ (ì—†ì–´ë„ ë¨)
    else:
        # ë™ì  LangGraph ìƒì„± ë° ì‹¤í–‰
        dynamic_graph = create_dynamic_graph(user_input.npc)
        response = dynamic_graph.invoke({
            "input": user_input.input,
            "npc": user_input.npc,
            "chat_history": []
        })

    # 4. ê¸°ì–µ ì €ì¥
    collection.add(
        documents=[f"{user_input.npc}: {user_input.input if user_input.npc == 'ì‚¬íšŒì' else response}"],
        metadatas=[{"npc": user_input.npc}],
        ids=[str(uuid.uuid4())]
    )

    return {
        "gpt_response": response,
        "memory_used": memory_used
    }

